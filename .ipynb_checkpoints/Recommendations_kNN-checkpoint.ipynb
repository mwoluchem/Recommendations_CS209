{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Using k-Nearest Neighbors to Identify User Ratings**\n",
    "\n",
    "This particular model uses a concept called neighborhood collaborative filtering to identify a small number of recommended restaurants for a particular user based on the same user's previously-stated preferences for similar restaurants. As was previously mentioned, the sample we are using for this model includes only those reviewers who have reviewed at least 150 restaurants previously, and thus the stated preferences are already present in the sample used for this model. \n",
    "\n",
    "The model included here is based on a solution to the same problem for CS109a in 2013. The documentation for this problem can be found here: http://nbviewer.jupyter.org/github/cs109/content/blob/master/HW4_solutions.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read in Data**\n",
    "\n",
    "The training and test samples used here were created previously prior to beginning analysis. They are the same training and test sets as have been used in previous models throughout this project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'Data/train/ON/train_150.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-bd693c2f2067>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Data/train/ON/train_150.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Data/test/ON/test_150.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/maiawoluchem/anaconda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/maiawoluchem/anaconda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/maiawoluchem/anaconda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/maiawoluchem/anaconda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    964\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    967\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/maiawoluchem/anaconda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1580\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1582\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1584\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__ (pandas/_libs/parsers.c:4209)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source (pandas/_libs/parsers.c:8873)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'Data/train/ON/train_150.csv' does not exist"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('Data/train/NC/train_150.csv')\n",
    "test_data = pd.read_csv('Data/test/ON/test_150.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30006, 13), (7584, 13))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_date</th>\n",
       "      <th>business_longitude</th>\n",
       "      <th>business_id</th>\n",
       "      <th>business_categories</th>\n",
       "      <th>business_name</th>\n",
       "      <th>business_state</th>\n",
       "      <th>review_score</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_average_rating</th>\n",
       "      <th>business_review_count</th>\n",
       "      <th>business_average_rating</th>\n",
       "      <th>business_latitude</th>\n",
       "      <th>user_review_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-08</td>\n",
       "      <td>-112.074080</td>\n",
       "      <td>GKg7N9i7djbigZ5fDj2DXw</td>\n",
       "      <td>['Restaurants', 'Cheesesteaks', 'Sandwiches']</td>\n",
       "      <td>Best of Philly</td>\n",
       "      <td>AZ</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-RhRXVW9z9fs5zzxhFfnHg</td>\n",
       "      <td>3.44</td>\n",
       "      <td>93</td>\n",
       "      <td>4.0</td>\n",
       "      <td>33.479487</td>\n",
       "      <td>415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-04-21</td>\n",
       "      <td>-112.110207</td>\n",
       "      <td>VRC7J-ahI4em9ddhihxq5w</td>\n",
       "      <td>['Restaurants', 'Salad', 'Pizza', 'Italian']</td>\n",
       "      <td>Pizza A Metro</td>\n",
       "      <td>AZ</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-RhRXVW9z9fs5zzxhFfnHg</td>\n",
       "      <td>3.44</td>\n",
       "      <td>315</td>\n",
       "      <td>4.5</td>\n",
       "      <td>33.480961</td>\n",
       "      <td>415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-10-19</td>\n",
       "      <td>-111.948604</td>\n",
       "      <td>H7kB4p-1BsbvL522cqASOQ</td>\n",
       "      <td>['Restaurants', 'Barbeque']</td>\n",
       "      <td>Bryan's Black Mountain Barbecue</td>\n",
       "      <td>AZ</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-RhRXVW9z9fs5zzxhFfnHg</td>\n",
       "      <td>3.44</td>\n",
       "      <td>304</td>\n",
       "      <td>4.0</td>\n",
       "      <td>33.832644</td>\n",
       "      <td>415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-09-07</td>\n",
       "      <td>-112.071895</td>\n",
       "      <td>5E_1xb3o97ZWQJiZJMVRmQ</td>\n",
       "      <td>['Restaurants', 'Delis', 'Breakfast &amp; Brunch',...</td>\n",
       "      <td>Einstein Bros Bagels</td>\n",
       "      <td>AZ</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-RhRXVW9z9fs5zzxhFfnHg</td>\n",
       "      <td>3.44</td>\n",
       "      <td>44</td>\n",
       "      <td>3.5</td>\n",
       "      <td>33.449824</td>\n",
       "      <td>415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-03-23</td>\n",
       "      <td>-112.047085</td>\n",
       "      <td>FirWX-Ep5203TsdiGgShKg</td>\n",
       "      <td>['Restaurants', 'American (New)']</td>\n",
       "      <td>The Vig Uptown</td>\n",
       "      <td>AZ</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-RhRXVW9z9fs5zzxhFfnHg</td>\n",
       "      <td>3.44</td>\n",
       "      <td>515</td>\n",
       "      <td>4.0</td>\n",
       "      <td>33.524431</td>\n",
       "      <td>415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  review_date  business_longitude             business_id  \\\n",
       "0  2010-01-08         -112.074080  GKg7N9i7djbigZ5fDj2DXw   \n",
       "1  2009-04-21         -112.110207  VRC7J-ahI4em9ddhihxq5w   \n",
       "2  2009-10-19         -111.948604  H7kB4p-1BsbvL522cqASOQ   \n",
       "3  2009-09-07         -112.071895  5E_1xb3o97ZWQJiZJMVRmQ   \n",
       "4  2010-03-23         -112.047085  FirWX-Ep5203TsdiGgShKg   \n",
       "\n",
       "                                 business_categories  \\\n",
       "0      ['Restaurants', 'Cheesesteaks', 'Sandwiches']   \n",
       "1       ['Restaurants', 'Salad', 'Pizza', 'Italian']   \n",
       "2                        ['Restaurants', 'Barbeque']   \n",
       "3  ['Restaurants', 'Delis', 'Breakfast & Brunch',...   \n",
       "4                  ['Restaurants', 'American (New)']   \n",
       "\n",
       "                     business_name business_state  review_score  \\\n",
       "0                   Best of Philly             AZ           4.0   \n",
       "1                    Pizza A Metro             AZ           4.0   \n",
       "2  Bryan's Black Mountain Barbecue             AZ           2.0   \n",
       "3             Einstein Bros Bagels             AZ           5.0   \n",
       "4                   The Vig Uptown             AZ           5.0   \n",
       "\n",
       "                  user_id  user_average_rating  business_review_count  \\\n",
       "0  -RhRXVW9z9fs5zzxhFfnHg                 3.44                     93   \n",
       "1  -RhRXVW9z9fs5zzxhFfnHg                 3.44                    315   \n",
       "2  -RhRXVW9z9fs5zzxhFfnHg                 3.44                    304   \n",
       "3  -RhRXVW9z9fs5zzxhFfnHg                 3.44                     44   \n",
       "4  -RhRXVW9z9fs5zzxhFfnHg                 3.44                    515   \n",
       "\n",
       "   business_average_rating  business_latitude  user_review_count  \n",
       "0                      4.0          33.479487                415  \n",
       "1                      4.5          33.480961                415  \n",
       "2                      4.0          33.832644                415  \n",
       "3                      3.5          33.449824                415  \n",
       "4                      4.0          33.524431                415  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Cleaning**\n",
    "\n",
    "Because this model is based on a user's previous experiences with similar restaurants, we need a way to define which restaurants in this dataset are similar to one another. One such measure is a \"common user support\", which shows the number of users who have rated any particular pair of restaurants. We need such a measurement because common user support can be used later throughout this problem as a proxy for how similar a pair of restaurants may be to each other.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-558033e28b5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mif\u001b[0m  \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mrest1_reviewers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbusiness_id\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mrest1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0mrest2_reviewers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbusiness_id\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mrest2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0mcommon_reviewers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrest1_reviewers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrest2_reviewers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0msupports\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommon_reviewers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/maiawoluchem/anaconda/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, other, axis)\u001b[0m\n\u001b[1;32m    859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mna_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m                 raise TypeError('Could not compare %s type with Series' %\n",
      "\u001b[0;32m/Users/maiawoluchem/anaconda/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mna_op\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_comp_method_OBJECT_ARRAY\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/maiawoluchem/anaconda/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36m_comp_method_OBJECT_ARRAY\u001b[0;34m(op, x, y)\u001b[0m\n\u001b[1;32m    743\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvec_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalar_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "restaurants=train_data.business_id.unique()\n",
    "supports=[]\n",
    "for i,rest1 in enumerate(restaurants):\n",
    "    for j,rest2 in enumerate(restaurants):\n",
    "        if  i < j:\n",
    "            rest1_reviewers = train_data[train_data.business_id==rest1].user_id.unique()\n",
    "            rest2_reviewers = train_data[train_data.business_id==rest2].user_id.unique()\n",
    "            common_reviewers = set(rest1_reviewers).intersection(rest2_reviewers)\n",
    "            supports.append(len(common_reviewers))\n",
    "print(\"Mean support is:\",np.mean(supports))\n",
    "plt.hist(supports)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Now that we have defined similar restaurants, we use this information to create a correlation measure that determines the ew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now create the pearson correlation coefficient between the newly corrected user ratings for users \n",
    "#who have reviewed the same restaurants. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats.stats import pearsonr\n",
    "def pearson_sim(rest1_reviews, rest2_reviews, n_common):\n",
    "    \"\"\"\n",
    "    Given a subframe of restaurant 1 reviews and a subframe of restaurant 2 reviews,\n",
    "    where the reviewers are those who have reviewed both restaurants, return \n",
    "    the pearson correlation coefficient between the user average subtracted ratings.\n",
    "    The case for zero common reviewers is handled separately. Its\n",
    "    ok to return a NaN if any of the individual variances are 0.\n",
    "    \"\"\"\n",
    "    if n_common==0:\n",
    "        rho=0.\n",
    "    else:\n",
    "        diff1=rest1_reviews['business_average_rating']-rest1_reviews['user_average_rating']\n",
    "        diff2=rest2_reviews['business_average_rating']-rest2_reviews['user_average_rating']\n",
    "        rho=pearsonr(diff1, diff2)[0]\n",
    "    return rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Ok but let's say you get a particular business. Here's a way to spit out the dataframe of the reviews for \n",
    "#that particular restaurant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_restaurant_reviews(restaurant_id, df, set_of_users):\n",
    "    \"\"\"\n",
    "    given a resturant id and a set of reviewers, return the sub-dataframe of their\n",
    "    reviews.\n",
    "    \"\"\"\n",
    "    mask = (df.user_id.isin(set_of_users)) & (df.business_id==restaurant_id)\n",
    "    reviews = df[mask]\n",
    "    reviews = reviews[reviews.user_id.duplicated()==False]\n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now that you have these reviews, calculate the similarity between restaurants at the database level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function\n",
    "--------\n",
    "calculate_similarity\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "rest1 : string\n",
    "    The id of restaurant 1\n",
    "rest2 : string\n",
    "    The id of restaurant 2\n",
    "df : DataFrame\n",
    "  A dataframe of reviews, such as the smalldf above\n",
    "similarity_func : func\n",
    "  A function like pearson_sim above which takes two dataframes of individual\n",
    "  restaurant reviews made by a common set of reviewers, and the number of\n",
    "  common reviews. This function returns the similarity of the two restaurants\n",
    "  based on the common reviews.\n",
    "  \n",
    "Returns\n",
    "--------\n",
    "A tuple\n",
    "  The first element of the tuple is the similarity and the second the\n",
    "  common support n_common. If the similarity is a NaN, set it to 0\n",
    "\"\"\"\n",
    "#your code here\n",
    "def calculate_similarity(rest1, rest2, df, similarity_func):\n",
    "    # find common reviewers\n",
    "    rest1_reviewers = df[df.business_id==rest1].user_id.unique()\n",
    "    rest2_reviewers = df[df.business_id==rest2].user_id.unique()\n",
    "    common_reviewers = set(rest1_reviewers).intersection(rest2_reviewers)\n",
    "    n_common=len(common_reviewers)\n",
    "    #get reviews\n",
    "    rest1_reviews = get_restaurant_reviews(rest1, df, common_reviewers)\n",
    "    rest2_reviews = get_restaurant_reviews(rest2, df, common_reviewers)\n",
    "    sim=similarity_func(rest1_reviews, rest2_reviews, n_common)\n",
    "    if np.isnan(sim):\n",
    "        return 0, n_common\n",
    "    return sim, n_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create now a database of similarities and common supporters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Database:\n",
    "    \"A class representing a database of similaries and common supports\"\n",
    "    \n",
    "    def __init__(self, df):\n",
    "        \"the constructor, takes a reviews dataframe like smalldf as its argument\"\n",
    "        database={}\n",
    "        self.df=df\n",
    "        self.uniquebizids={v:k for (k,v) in enumerate(df.business_id.unique())}\n",
    "        keys=self.uniquebizids.keys()\n",
    "        l_keys=len(keys)\n",
    "        self.database_sim=np.zeros([l_keys,l_keys])\n",
    "        self.database_sup=np.zeros([l_keys, l_keys], dtype=np.int)\n",
    "        \n",
    "    def populate_by_calculating(self, similarity_func):\n",
    "        \"\"\"\n",
    "        a populator for every pair of businesses in df. takes similarity_func like\n",
    "        pearson_sim as argument\n",
    "        \"\"\"\n",
    "        items=self.uniquebizids.items()\n",
    "        for b1, i1 in items:\n",
    "            for b2, i2 in items:\n",
    "                if i1 < i2:\n",
    "                    sim, nsup=calculate_similarity(b1, b2, self.df, similarity_func)\n",
    "                    self.database_sim[i1][i2]=sim\n",
    "                    self.database_sim[i2][i1]=sim\n",
    "                    self.database_sup[i1][i2]=nsup\n",
    "                    self.database_sup[i2][i1]=nsup\n",
    "                elif i1==i2:\n",
    "                    nsup=self.df[self.df.business_id==b1].user_id.count()\n",
    "                    self.database_sim[i1][i1]=1.\n",
    "                    self.database_sup[i1][i1]=nsup\n",
    "                    \n",
    "\n",
    "    def get(self, b1, b2):\n",
    "        \"returns a tuple of similarity,common_support given two business ids\"\n",
    "        sim=self.database_sim[self.uniquebizids[b1]][self.uniquebizids[b2]]\n",
    "        nsup=self.database_sup[self.uniquebizids[b1]][self.uniquebizids[b2]]\n",
    "        return (sim, nsup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now let's make the database and save it as db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.seterr(all='raise')\n",
    "db=Database(train_data)\n",
    "db.populate_by_calculating(pearson_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#db.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Find the nearest restaurants based on what the user has already rated themselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function\n",
    "--------\n",
    "knearest_amongst_userrated\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "restaurant_id : string\n",
    "    The id of the restaurant whose nearest neighbors we want\n",
    "user_id : string\n",
    "    The id of the user, in whose reviewed restaurants we want to find the neighbors\n",
    "df: Dataframe\n",
    "    The dataframe of reviews such as smalldf\n",
    "dbase : instance of Database class.\n",
    "    A database of similarities, on which the get method can be used to get the similarity\n",
    "  of two businessed. e.g. dbase.get(rid1,rid2)\n",
    "k : int\n",
    "    the number of nearest neighbors desired, default 7\n",
    "reg: float\n",
    "    the regularization.\n",
    "    \n",
    "  \n",
    "Returns\n",
    "--------\n",
    "A sorted list\n",
    "    of the top k similar restaurants. The list is a list of tuples\n",
    "    (business_id, shrunken similarity, common support).\n",
    "\"\"\"\n",
    "#your code here\n",
    "def knearest_amongst_userrated(restaurant_id, user_id, df, dbase, k=7, reg=3.):\n",
    "    dfuser=df[df.user_id==user_id]\n",
    "    bizsuserhasrated=dfuser.business_id.unique()\n",
    "    return knearest(restaurant_id, bizsuserhasrated, dbase, k=k, reg=reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Return the predicted rating someone might give to a particular restaurant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Function\n",
    "--------\n",
    "rating\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "df: Dataframe\n",
    "    The dataframe of reviews such as smalldf\n",
    "dbase : instance of Database class.\n",
    "    A database of similarities, on which the get method can be used to get the similarity\n",
    "  of two businessed. e.g. dbase.get(rid1,rid2)\n",
    "restaurant_id : string\n",
    "    The id of the restaurant whose nearest neighbors we want\n",
    "user_id : string\n",
    "    The id of the user, in whose reviewed restaurants we want to find the neighbors\n",
    "k : int\n",
    "    the number of nearest neighbors desired, default 7\n",
    "reg: float\n",
    "    the regularization.\n",
    "    \n",
    "  \n",
    "Returns\n",
    "--------\n",
    "A float\n",
    "    which is the impued rating that we predict that user_id will make for restaurant_id\n",
    "\"\"\"\n",
    "#your code here\n",
    "def rating(df, dbase, restaurant_id, user_id, k=7, reg=3.):\n",
    "    mu=df.stars.mean()\n",
    "    users_reviews=df[df.user_id==user_id]\n",
    "    nsum=0.\n",
    "    scoresum=0.\n",
    "    nears=knearest_amongst_userrated(restaurant_id, user_id, df, dbase, k=k, reg=reg)\n",
    "    restaurant_mean=df[df.business_id==restaurant_id].business_avg.values[0]\n",
    "    user_mean=users_reviews.user_avg.values[0]\n",
    "    scores=[]\n",
    "    for r,s,nc in nears:\n",
    "        scoresum=scoresum+s\n",
    "        scores.append(s)\n",
    "        r_reviews_row=users_reviews[users_reviews['business_id']==r]\n",
    "        r_stars=r_reviews_row.stars.values[0]\n",
    "        r_avg=r_reviews_row.business_avg.values[0]\n",
    "        rminusb=(r_stars - (r_avg + user_mean - mu))\n",
    "        nsum=nsum+s*rminusb\n",
    "    baseline=(user_mean +restaurant_mean - mu)\n",
    "    #we might have nears, but there might be no commons, giving us a pearson of 0\n",
    "    if scoresum > 0.:\n",
    "        val =  nsum/scoresum + baseline\n",
    "    else:\n",
    "        val=baseline\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
